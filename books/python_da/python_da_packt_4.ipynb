{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packt >\n",
    "# Python Data Analysis - Third Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistics\n",
    "\n",
    "**Exploratory data analysis (EDA)** is the first step toward data analysis and building a machine learning model. Statistics provide fundamental knowledge and a set of tools for exploratory or descriptive data analysis.\n",
    "\n",
    "Statistics a primary and very necessary skill for data professionals, helping them gain initial insights and an understanding of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types of attributes\n",
    "\n",
    "The data type of attributes helps analysts select the correct method for data analysis and visualization plots. \n",
    "___\n",
    "1. **Nominal (categorical) attributes**: Nominal refers to names or labels of categorized variables. The values are categorical, qualitative, and unordered in nature such as product name, brand name, zip code, state, gender, and marital status. Data analysts can calculate the mode, which is the most commonly occurring value. \n",
    "2. **Ordinal attributes**: Ordinal refers to names or labels with a meaningful order or ranking. These types of attributes measure subjective qualities alone. That is why they are used in surveys for customer satisfaction ratings, product ratings, and movie rating reviews.\n",
    "3. **Numeric attributes**: A numeric attribute is quantitatively presented as integer or real values. Numeric attributes can be of two types: **interval-scaled** or **ratio-scaled**\n",
    "- **interval-scaled** attributes are measured on an ordered scale of equal-sized units. The main problem with interval-scaled attribute values is that they don't have a \"true zero\"—for example, if the temperature in °C is 0 then it doesn't mean that temperature doesn't exist. Interval-scaled data can add and subtract but can't multiply and divide because of no true zero. We can also calculate the mean value of an interval-scaled attribute, in addition to the median and mode.\n",
    "- **ratio-scaled** attributes are measured on an ordered scale of equal-sized units, similar to an interval scale with an inherent zero point. Examples of ratio-scaled attributes are height, weight, latitude, longitude, years of experience, and the number of words in a document. We can perform multiplication and division, and calculate the difference between ratio-scaled values. We can also compute central tendency measures such as mean, median, and mode. The Celsius and Fahrenheit temperature scales are measured on an interval scale, while the Kelvin temperature scale is measured on a ratio scale because it has a true zero point. \n",
    "___\n",
    "\n",
    "Discrete and continuous attributes\n",
    "\n",
    "- a **discrete** variable accepts only a countable finite number, such as how many students are present in a class, how many cars are sold, and how many books are published. It can be obtained by counting numbers\n",
    "- a **continuous** variable accepts an infinite number of possible values, such as the weight and height of students. It can be obtained by measuring.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean\n",
    "\n",
    "The mean value is computed by the sum of observations divided by the number of observations. It is sensitive to outliers and noise, with the result that whenever uncommon or unusual values are added to a group, its mean gets deviated from the typical central value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = {'name': ['John', 'Alia', 'Ananya', 'Steve', 'Ben'],\n",
    "              'gender': ['M', 'F', 'F', 'M', 'M'],\n",
    "              'communication_skill_score': [40, 45, 23, 39, 39],\n",
    "              'quantitative_skill_score': [38, 41, 42, 48, 32]}\n",
    "df = pd.DataFrame(sample_data, columns=['name', 'gender', 'communication_skill_score', 'quantitative_skill_score'])\n",
    "df['communication_skill_score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mode\n",
    "\n",
    "The mode is the highest-occurring item in a group of observations. The mode value occurs frequently in data and is mostly used for categorical values. If all the values in a group are unique or non-repeated, then there is no mode. It is also possible that more than one value has the same occurrence frequency. In such cases, there can be multiple modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    39\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['communication_skill_score'].mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median\n",
    "\n",
    "The median is the midpoint or middle value in a group of observations. It is also called the 50th percentile. The median is less affected by outliers and noise than the mean, and that is why it is considered a more suitable statistic measure for reporting. It is much near to a typical central value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['communication_skill_score'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dispersion\n",
    "\n",
    "Dispersion metrics measure the deviation in observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the range is the difference between the maximum and minimum value of an observation\n",
    "communication_skill_score_range = df['communication_skill_score'].max() - df['communication_skill_score'].min()\n",
    "communication_skill_score_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# IQR (interquartile range) is the difference between the third and first quartiles\n",
    "# it measures the middle 50% in the observation\n",
    "# it represents the range where most of the observation lies\n",
    "q1 = df['communication_skill_score'].quantile(.25)\n",
    "q2 = df['communication_skill_score'].quantile(.75)\n",
    "iqr = q2 - q1\n",
    "iqr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.2"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the variance measures the deviation from the mean\n",
    "# it is the average value of the squared difference between observed values and the mean\n",
    "# The main problem with the variance is its unit of measurement \n",
    "# because of squaring the difference between observations and mean.\n",
    "df['communication_skill_score'].var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.318653737234168"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the standard deviation unit is the same as for the original observations\n",
    "# this makes it easier for an analyst to evaluate the exact deviation from the mean\n",
    "df['communication_skill_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communication_skill_score</th>\n",
       "      <th>quantitative_skill_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>37.200000</td>\n",
       "      <td>40.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.318654</td>\n",
       "      <td>5.848077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>23.000000</td>\n",
       "      <td>32.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>39.000000</td>\n",
       "      <td>41.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>40.000000</td>\n",
       "      <td>42.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>45.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       communication_skill_score  quantitative_skill_score\n",
       "count                   5.000000                  5.000000\n",
       "mean                   37.200000                 40.200000\n",
       "std                     8.318654                  5.848077\n",
       "min                    23.000000                 32.000000\n",
       "25%                    39.000000                 38.000000\n",
       "50%                    39.000000                 41.000000\n",
       "75%                    40.000000                 42.000000\n",
       "max                    45.000000                 48.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skewness and kurtosis\n",
    "___\n",
    "**Skewness** measures the symmetry of a distribution. It shows how much the distribution deviates from a normal distribution. Its values can be zero, positive, and negative. A zero value represents a perfectly normal shape of a distribution. Positive skewness is shown by the tails pointing toward the right—that is, outliers are skewed to the right and data stacked up on the left. Negative skewness is shown by the tails pointing toward the left—that is, outliers are skewed to the left and data stacked up on the right. Positive skewness occurs when the mean is greater than the median and the mode. Negative skewness occurs when the mean is less than the median and mode. \n",
    "___\n",
    "**Kurtosis** measures the tailedness (thickness of tail) compared to a normal distribution. High kurtosis is heavy-tailed, which means more outliers are present in the observations, and low values of kurtosis are light-tailed, which means fewer outliers are present in the observations. There are three types of kurtosis shapes: mesokurtic, platykurtic, and leptokurtic. \n",
    "\n",
    "- A normal distribution having zero kurtosis is known as a **mesokurtic** distribution.\n",
    "- A **platykurtic** distribution has a negative kurtosis value and is thin-tailed compared to a normal distribution.\n",
    "- A **leptokurtic** distribution has a kurtosis value greater than 3 and is fat-tailed compared to a normal distribution. \n",
    "\n",
    "<img src='img/kurtosis.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.704679180800373"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['communication_skill_score'].skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6010641852384015"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['communication_skill_score'].kurtosis()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance and correlation coefficients\n",
    "\n",
    "**Covariance** measures the relationship between a pair of variables. It shows the degree of change in the variables—that is, how the change in one variable affects the other variable. Its value ranges from -infinity to + infinity. The problem with covariance is that it does not provide effective conclusions because it is not normalized. \n",
    "\n",
    "**Correlation** shows how variables are correlated with each other. Correlation offers a better understanding than covariance and is a normalized version of covariance. Correlation ranges from -1 to 1. A negative value represents the increase in one variable, causing a decrease in other variables or variables to move in the same direction. A positive value represents the increase in one variable, causing an increase in another variable, or a decrease in one variable causes decreases in another variable. A zero value means that there is no relationship between the variable or that variables are independent of each other. \n",
    "\n",
    "- **pearson**: Standard correlation coefficient\n",
    "- **kendall**: Kendall's tau correlation coefficient\n",
    "- **spearman**: Spearman's rank correlation coefficient\n",
    "\n",
    "**Spearman's rank correlation coefficient** is Pearson's correlation coefficient on the ranks of the observations. It is a non-parametric measure for rank correlation. It assesses the strength of the association between two ranked variables. Ranked variables are ordinal numbers, arranged in order. First, we rank the observations and then compute the correlation of ranks. It can apply to both continuous and discrete ordinal variables. When the distribution of data is skewed or an outlier is affected, then Spearman's rank correlation is used instead of Pearson's correlation because it doesn't have any assumptions for data distribution.\n",
    "\n",
    "**Kendall's rank correlation coefficient** or Kendall's tau coefficient is a non-parametric statistic used to measure the association between two ordinal variables. It is a type of rank correlation. It measures the similarity or dissimilarity between two variables. If both the variables are binary, then Pearson's = Spearman's = Kendall's tau. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communication_skill_score</th>\n",
       "      <th>quantitative_skill_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>communication_skill_score</th>\n",
       "      <td>69.20</td>\n",
       "      <td>-6.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantitative_skill_score</th>\n",
       "      <td>-6.55</td>\n",
       "      <td>34.20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           communication_skill_score  quantitative_skill_score\n",
       "communication_skill_score                      69.20                     -6.55\n",
       "quantitative_skill_score                       -6.55                     34.20"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.cov()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communication_skill_score</th>\n",
       "      <th>quantitative_skill_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>communication_skill_score</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>-0.13464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantitative_skill_score</th>\n",
       "      <td>-0.13464</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           communication_skill_score  quantitative_skill_score\n",
       "communication_skill_score                    1.00000                  -0.13464\n",
       "quantitative_skill_score                    -0.13464                   1.00000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method ='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communication_skill_score</th>\n",
       "      <th>quantitative_skill_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>communication_skill_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.307794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantitative_skill_score</th>\n",
       "      <td>-0.307794</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           communication_skill_score  quantitative_skill_score\n",
       "communication_skill_score                   1.000000                 -0.307794\n",
       "quantitative_skill_score                   -0.307794                  1.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method ='spearman')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>communication_skill_score</th>\n",
       "      <th>quantitative_skill_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>communication_skill_score</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.105409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantitative_skill_score</th>\n",
       "      <td>-0.105409</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           communication_skill_score  quantitative_skill_score\n",
       "communication_skill_score                   1.000000                 -0.105409\n",
       "quantitative_skill_score                   -0.105409                  1.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.corr(method ='kendall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Central limit theorem\n",
    "\n",
    "Data analysis methods involve hypothesis testing and deciding confidence intervals. All statistical tests assume that the population is normally distributed. The central limit theorem is the core of hypothesis testing. According to this theorem, the sampling distribution approaches a normal distribution with an increase in the sample size. Also, the mean of the sample gets closer to the population means and the standard deviation of the sample gets reduced. This theorem is essential for working with inferential statistics,  helping data analysts figure out how samples can be useful in getting insights about the population.\n",
    "\n",
    "Does it provide answers to questions such as what size of sample should be taken or which sample size is an accurate representation of the population? You can understand this with the help of the following diagram:\n",
    "\n",
    "<img src='img/sample_sizes.png'>\n",
    "\n",
    "As the sample size increases, the histogram approaches a normal curve."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collecting samples\n",
    "\n",
    "Sampling is a method or process of collecting sample data from various sources. It is the most crucial part of data collection. The success of an experiment depends upon how well the data is collected. If anything goes wrong with sampling, it will hugely affect the final interpretations. \n",
    "\n",
    "Sampling helps researchers to infer the population from the sample and reduces the survey cost and workload to collect and manage data. \n",
    "\n",
    "1. **Probability sampling**: With this technique, there is a random selection of every respondent of the population, with an equal chance of the selected sample. Such types of sampling techniques are more time-consuming and expensive, and include the following:\n",
    "- *Simple random sampling*: each respondent is selected by chance, meaning that each respondent has an equal chance of being selected.\n",
    "- *Stratified sampling*: the whole population is divided into small groups known as strata that are based on some similarity criteria. These strata can be of unequal size. This technique improves accuracy by reducing selection bias.\n",
    "- *Systematic sampling*: respondents are selected at regular intervals. In other words, we can say respondents are selected in systematic order from the target population, such as every nth respondent from the population.\n",
    "- *Cluster sampling*: the entire population is divided into clusters or sections. Clusters are formed based on gender, location, occupation, and so on. These entire clusters are used for sampling rather than the individual respondent.\n",
    "\n",
    "2. **Non-probability sampling**: This sampling non-randomly selects every respondent of the population, with an unequal chance of the selected sample. Its outcome might be biased. Such types of sampling techniques are cheaper and more convenient, and include the following:\n",
    "- *Convenience sampling*: selects respondents based on their availability and willingness to participate. Statisticians prefer this technique for the initial survey due to cost and fast collection of data, but the results are more prone to bias.\n",
    "- *Purposive sampling*: This is also known as judgmental sampling because it depends upon the statistician's judgment. Statisticians decide at runtime who will participate in the survey based on certain predefined characteristics. News reporters use this technique to select people whose opinions they wish to obtain.\n",
    "- *Quota sampling*: This technique predefines the properties of strata and proportions for the sample. Sample respondents are selected until a definitive proportion is met. It differs from stratified sampling in terms of selection strategy; it selects items in strata using random sampling.\n",
    "- *Snowball sampling*: This technique is used in a situation where finding respondents in a population is rare and difficult to trace, in areas such as illegal immigration or HIV. Statisticians contact volunteers to reach out to the victims. It is also known as referral sampling because the initial person taking part in the survey refers to another person who fits the sample description."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing parametric tests\n",
    "\n",
    "A *t-test* is a kind of parametric test that is used for checking if there is a significant difference between the means of the two groups concerned. It is the most commonly used inferential statistic that follows the normal distribution. A t-test has two types: a one-sample t-test and a two-sample t-test. \n",
    "\n",
    "A **one-sample t-test** is used for checking if there is a significant difference between a sample and hypothesized population means. \n",
    "\n",
    "A **two-sample t-test** is used for comparing the significant difference between two independent groups. This test is also known as an independent samples t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import ttest_1samp\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.5"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.array([63, 75, 84, 58, 52, 96, 63, 55, 76, 83])\n",
    "mean_value = np.mean(data)\n",
    "mean_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P Value: 0.5986851106160134\n",
      "t-test Value: 0.5454725779039431\n",
      "Hypothesis Accepted\n"
     ]
    }
   ],
   "source": [
    "t_test_value, p_value = ttest_1samp(data, 68)\n",
    "print(\"P Value:\",p_value)\n",
    "print(\"t-test Value:\",t_test_value)\n",
    "# 0.05 or 5% is significance level or alpha.\n",
    "if p_value < 0.05: \n",
    "    print(\"Hypothesis Rejected\")\n",
    "else:  \n",
    "    print(\"Hypothesis Accepted\")\n",
    "# the output results have shown that the null hypothesis is accepted with a 95% confidence interval, \n",
    "# which means that the average weight of 10 students is 68 kg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2=np.array([53, 43, 31, 113, 33, 57, 27, 23, 24, 43])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-values: 0.015170931362451255\n",
      "t-test: 2.6835879913819185\n",
      "Hypothesis Rejected\n"
     ]
    }
   ],
   "source": [
    "# Compare samples\n",
    "stat, p = ttest_ind(data, data2)\n",
    "print(\"p-values:\",p)\n",
    "print(\"t-test:\",stat)\n",
    "\n",
    "# 0.05 or 5% is significance level or alpha.\n",
    "if p < 0.05: \n",
    "    print(\"Hypothesis Rejected\")\n",
    "else:\n",
    "    print(\"Hypothesis Accepted\") \n",
    "# we have tested the hypothesis average weight of two groups using the ttest_ind() method, \n",
    "# and results show that the null hypothesis is rejected with a 95% confidence interval, \n",
    "# which means that the sample means are different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
